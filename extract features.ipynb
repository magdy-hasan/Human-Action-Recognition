{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model.layers.pop()\n",
    "model = Model(model.inputs,model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vgg16_features(video_input_file_path):\n",
    "    count = 0\n",
    "    #print('Extracting frames from video: ', video_input_file_path)\n",
    "    vidcap = cv2.VideoCapture(video_input_file_path)\n",
    "    success, image = vidcap.read()\n",
    "    features = []\n",
    "    success = True\n",
    "    while success:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, (count * 1000))  # added this line\n",
    "        success, image = vidcap.read()\n",
    "        # print('Read a new frame: ', success)\n",
    "        if success:\n",
    "            img = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "            input = img_to_array(img)\n",
    "            input = np.expand_dims(input, axis=0)\n",
    "            input = preprocess_input(input)\n",
    "            feature = model.predict(input).ravel()\n",
    "            features.append(feature)\n",
    "            count = count + 1\n",
    "    unscaled_features = np.array(features)\n",
    "    #np.save(feature_output_file_path, unscaled_features)\n",
    "    return unscaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = []\n",
    "x_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir_path = 'UCF-101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_data_dir_path = 'vgg16-features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_count = 0\n",
    "for f in os.listdir(input_data_dir_path):\n",
    "    file_path = input_data_dir_path + os.path.sep + f\n",
    "    output_dir_name = f\n",
    "    output_dir_path = output_feature_data_dir_path + os.path.sep + output_dir_name\n",
    "    dir_count += 1\n",
    "    for ff in os.listdir(file_path):\n",
    "        video_file_path = file_path + os.path.sep + ff\n",
    "        #output_feature_file_path = output_dir_path + os.path.sep + ff.split('.')[0] + '.npy'\n",
    "        x = extract_vgg16_features(video_file_path)\n",
    "        y = f\n",
    "        #print(x.shape)\n",
    "        y_samples.append(y)\n",
    "        x_samples.append(x)\n",
    "    print(dir_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x_samples)\n",
    "y = np.array(y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xf.npy', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('yf.npy', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save here before continue because this steps took a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = np.load('xf.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = np.load('yf.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_list = []\n",
    "for x in x_samples:\n",
    "    frames = x.shape[0]\n",
    "    frames_list.append(frames)\n",
    "    max_frames = max(frames, max_frames)\n",
    "expected_frames = int(np.mean(frames_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13320"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.zeros((1,7,4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 7, 4096)\n",
      "1000 (1002, 7, 4096)\n",
      "2000 (2002, 7, 4096)\n",
      "3000 (3002, 7, 4096)\n",
      "4000 (4002, 7, 4096)\n",
      "5000 (5002, 7, 4096)\n",
      "6000 (6002, 7, 4096)\n",
      "7000 (7002, 7, 4096)\n",
      "8000 (8002, 7, 4096)\n",
      "9000 (9002, 7, 4096)\n",
      "10000 (10002, 7, 4096)\n",
      "11000 (11002, 7, 4096)\n",
      "12000 (12002, 7, 4096)\n",
      "13000 (13002, 7, 4096)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_samples)):\n",
    "    #print(i)\n",
    "    x = x_samples[i]\n",
    "    frames = x.shape[0]\n",
    "    if frames >= expected_frames:\n",
    "        x = x[0:expected_frames, :]\n",
    "        xt =  np.concatenate((xt,x.reshape((1,x.shape[0],x.shape[1]))),axis=0)\n",
    "    elif frames < expected_frames:\n",
    "        temp = np.zeros(shape=(expected_frames, x.shape[1]))\n",
    "        temp[0:frames, :] = x\n",
    "        xt =  np.concatenate((xt,temp.reshape((1,temp.shape[0],temp.shape[1]))),axis=0)\n",
    "    if i % 1000==0:\n",
    "        print(i, xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Archery': 0, 'Knitting': 1, 'PlayingDaf': 2, 'CricketBowling': 3, 'HammerThrow': 4, 'GolfSwing': 5, 'Skiing': 6, 'JugglingBalls': 7, 'SalsaSpin': 8, 'BenchPress': 9, 'Fencing': 10, 'WritingOnBoard': 11, 'PommelHorse': 12, 'IceDancing': 13, 'Rowing': 14, 'CliffDiving': 15, 'PullUps': 16, 'Diving': 17, 'VolleyballSpiking': 18, 'BoxingPunchingBag': 19, 'PlayingSitar': 20, 'Billiards': 21, 'FieldHockeyPenalty': 22, 'PlayingCello': 23, 'PlayingTabla': 24, 'BreastStroke': 25, 'SumoWrestling': 26, 'Biking': 27, 'HorseRiding': 28, 'ApplyEyeMakeup': 29, 'Bowling': 30, 'TennisSwing': 31, 'Hammering': 32, 'BasketballDunk': 33, 'PushUps': 34, 'ApplyLipstick': 35, 'TrampolineJumping': 36, 'PoleVault': 37, 'ThrowDiscus': 38, 'BrushingTeeth': 39, 'TaiChi': 40, 'Surfing': 41, 'Rafting': 42, 'PlayingPiano': 43, 'BalanceBeam': 44, 'HandstandPushups': 45, 'WalkingWithDog': 46, 'Mixing': 47, 'MilitaryParade': 48, 'SoccerJuggling': 49, 'JumpRope': 50, 'Kayaking': 51, 'BaseballPitch': 52, 'LongJump': 53, 'PlayingFlute': 54, 'HighJump': 55, 'HandstandWalking': 56, 'CuttingInKitchen': 57, 'CricketShot': 58, 'BlowingCandles': 59, 'PizzaTossing': 60, 'PlayingViolin': 61, 'Drumming': 62, 'Lunges': 63, 'ShavingBeard': 64, 'BoxingSpeedBag': 65, 'BodyWeightSquats': 66, 'BlowDryHair': 67, 'PlayingDhol': 68, 'HulaHoop': 69, 'Haircut': 70, 'HorseRace': 71, 'RopeClimbing': 72, 'Shotput': 73, 'SkateBoarding': 74, 'FrisbeeCatch': 75, 'FloorGymnastics': 76, 'Swing': 77, 'StillRings': 78, 'MoppingFloor': 79, 'SoccerPenalty': 80, 'WallPushups': 81, 'JumpingJack': 82, 'PlayingGuitar': 83, 'SkyDiving': 84, 'CleanAndJerk': 85, 'HeadMassage': 86, 'BandMarching': 87, 'FrontCrawl': 88, 'YoYo': 89, 'ParallelBars': 90, 'TableTennisShot': 91, 'BabyCrawling': 92, 'Punch': 93, 'Nunchucks': 94, 'Skijet': 95, 'JavelinThrow': 96, 'Typing': 97, 'Basketball': 98, 'RockClimbingIndoor': 99, 'UnevenBars': 100}\n"
     ]
    }
   ],
   "source": [
    "labels = dict()\n",
    "for y in y_samples:\n",
    "    if y not in labels:\n",
    "        labels[y] = len(labels)\n",
    "print(labels)\n",
    "for i in range(len(y_samples)):\n",
    "    y_samples[i] = labels[y_samples[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13321, 7, 4096)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(x_samples)\n",
    "y = np.array(y_samples)\n",
    "y = to_categorical(y,num_classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = xt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13320, 7, 4096) (13320, 101)\n"
     ]
    }
   ],
   "source": [
    "print(xt.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xfe.npy', xt)\n",
    "np.save('yfe.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
